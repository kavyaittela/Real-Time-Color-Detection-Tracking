{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Py4OW-0owVY"
      },
      "outputs": [],
      "source": [
        "# STEP 1: clean + install a fresh OpenCV that works with current NumPy\n",
        "!pip uninstall -y opencv-python opencv-python-headless\n",
        "\n",
        "# install latest compatible headless OpenCV (works with NumPy 2.x)\n",
        "!pip install -q opencv-python-headless\n",
        "\n",
        "# quick test\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2, numpy as np\n",
        "\n",
        "print(\"OpenCV version:\", cv2.__version__)\n",
        "print(\"NumPy version:\", np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REAL-TIME COLOR DETECTOR & TRACKER (PROJECT CODE) --------------------------\n",
        "from IPython.display import clear_output\n",
        "from google.colab import output\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2, numpy as np, time\n",
        "from base64 import b64decode\n",
        "\n",
        "# JS: capture one frame from browser webcam\n",
        "capture_js = \"\"\"\n",
        "async function captureFrame(quality=0.85, timeout_ms=5000) {\n",
        "  const start = performance.now();\n",
        "  let stream = null;\n",
        "  try {\n",
        "    stream = await navigator.mediaDevices.getUserMedia({video: true, audio: false});\n",
        "  } catch(e) {\n",
        "    return {error: 'getUserMedia failed: ' + e.toString()};\n",
        "  }\n",
        "  const video = document.createElement('video');\n",
        "  video.srcObject = stream;\n",
        "  video.playsInline = true;\n",
        "  try { await video.play(); } catch(e) {}\n",
        "\n",
        "  // wait until video has valid size or timeout\n",
        "  while ((video.videoWidth === 0 || video.videoHeight === 0) &&\n",
        "         (performance.now() - start) < timeout_ms) {\n",
        "    await new Promise(r => setTimeout(r, 50));\n",
        "  }\n",
        "\n",
        "  if (video.videoWidth === 0 || video.videoHeight === 0) {\n",
        "    stream.getTracks().forEach(t => t.stop());\n",
        "    return {error: 'camera did not provide dimensions in time'};\n",
        "  }\n",
        "\n",
        "  const canvas = document.createElement('canvas');\n",
        "  canvas.width = video.videoWidth;\n",
        "  canvas.height = video.videoHeight;\n",
        "  const ctx = canvas.getContext('2d');\n",
        "  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "  stream.getTracks().forEach(track => track.stop());\n",
        "  const dataUrl = canvas.toDataURL('image/png', quality);\n",
        "  return {data: dataUrl};\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def grab_frame(quality=0.8, tries=2):\n",
        "  \"\"\"Capture single frame from webcam via JS and return as BGR image.\"\"\"\n",
        "  for _ in range(tries):\n",
        "    result = output.eval_js(capture_js + f\"captureFrame({quality}, 5000)\")\n",
        "    if not result:\n",
        "      time.sleep(0.3)\n",
        "      continue\n",
        "\n",
        "    # handle dict or string\n",
        "    if isinstance(result, dict) and 'error' in result:\n",
        "      raise RuntimeError(\"JS error: \" + result['error'])\n",
        "\n",
        "    data_url = None\n",
        "    if isinstance(result, dict) and 'data' in result:\n",
        "      data_url = result['data']\n",
        "    elif isinstance(result, str) and result.startswith(\"data:image\"):\n",
        "      data_url = result\n",
        "    else:\n",
        "      s = str(result)\n",
        "      if \"data:image\" in s:\n",
        "        idx = s.find(\"data:image\")\n",
        "        data_url = s[idx:]\n",
        "\n",
        "    if not data_url:\n",
        "      time.sleep(0.2)\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      header, b64 = data_url.split(',', 1)\n",
        "      img_bytes = b64decode(b64)\n",
        "      nparr = np.frombuffer(img_bytes, np.uint8)\n",
        "      img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "      return img\n",
        "    except Exception as e:\n",
        "      raise RuntimeError(\"Failed to decode frame: \" + str(e))\n",
        "\n",
        "  raise RuntimeError(\"Failed to capture a frame from camera.\")\n",
        "\n",
        "# HSV COLOR RANGES -----------------------------------------------------------\n",
        "COLOR_RANGES = {\n",
        "    \"red1\":  ((0, 120, 70),  (10, 255, 255)),\n",
        "    \"red2\":  ((170, 120, 70),(180, 255, 255)),\n",
        "    \"green\": ((35, 80, 40),  (85, 255, 255)),\n",
        "    \"blue\":  ((90, 60, 40),  (140, 255, 255)),\n",
        "    \"yellow\":((15, 120, 120),(35, 255, 255)),\n",
        "    \"orange\":((10, 120, 100),(25, 255, 255)),\n",
        "    \"pink\":  ((145, 80, 80), (170, 255, 255)),\n",
        "}\n",
        "\n",
        "def detect_and_track(frame, color_name=\"green\", min_area=1000, debug=False):\n",
        "  \"\"\"Detect given color in frame and draw circle + centroid on it.\"\"\"\n",
        "  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # handle red as 2 ranges\n",
        "  if color_name == \"red\":\n",
        "    m1 = cv2.inRange(hsv, np.array(COLOR_RANGES[\"red1\"][0]),\n",
        "                          np.array(COLOR_RANGES[\"red1\"][1]))\n",
        "    m2 = cv2.inRange(hsv, np.array(COLOR_RANGES[\"red2\"][0]),\n",
        "                          np.array(COLOR_RANGES[\"red2\"][1]))\n",
        "    mask = cv2.bitwise_or(m1, m2)\n",
        "  else:\n",
        "    if color_name not in COLOR_RANGES:\n",
        "      raise ValueError(f\"Unknown color: {color_name}\")\n",
        "    lower, upper = COLOR_RANGES[color_name]\n",
        "    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
        "\n",
        "  # clean mask\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
        "  mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "  mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "  mask = cv2.GaussianBlur(mask, (7,7), 0)\n",
        "\n",
        "  contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  annotated = frame.copy()\n",
        "\n",
        "  if contours:\n",
        "    c = max(contours, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(c)\n",
        "    if area > min_area:\n",
        "      (x,y), r = cv2.minEnclosingCircle(c)\n",
        "      M = cv2.moments(c)\n",
        "      if M[\"m00\"] != 0:\n",
        "        cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
        "      else:\n",
        "        cx, cy = int(x), int(y)\n",
        "\n",
        "      cv2.circle(annotated, (int(x), int(y)), int(r), (0,255,0), 2)\n",
        "      cv2.circle(annotated, (cx, cy), 5, (0,0,255), -1)\n",
        "      cv2.putText(annotated, f\"{color_name} area:{int(area)}\", (10,30),\n",
        "                  cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
        "\n",
        "      if debug:\n",
        "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "        h,w = annotated.shape[:2]\n",
        "        small = cv2.resize(mask_bgr, (w//4, h//4))\n",
        "        annotated[0:h//4, w - w//4 : w] = small\n",
        "\n",
        "      return annotated, (cx, cy), area\n",
        "\n",
        "  # if nothing detected\n",
        "  cv2.putText(annotated, f\"No {color_name} detected\", (10,30),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
        "  return annotated, None, 0\n",
        "\n",
        "def run_color_tracker(color=\"green\", max_frames=200, delay=0.12,\n",
        "                      min_area=1200, debug=False):\n",
        "  \"\"\"Main loop for real-time tracking.\"\"\"\n",
        "  print(\"Starting camera. Allow webcam permission in the browser.\")\n",
        "  time.sleep(0.5)\n",
        "  for i in range(max_frames):\n",
        "    try:\n",
        "      frame = grab_frame(quality=0.7, tries=2)\n",
        "    except Exception as e:\n",
        "      print(\"Capture error:\", e)\n",
        "      return\n",
        "\n",
        "    annotated, centroid, area = detect_and_track(\n",
        "        frame, color_name=color, min_area=min_area, debug=debug\n",
        "    )\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f\"Frame {i+1}/{max_frames} — Tracking: {color} — area: {area}\")\n",
        "    cv2_imshow(annotated)\n",
        "    time.sleep(delay)\n",
        "\n",
        "  print(\"Finished.\")\n",
        "\n",
        "print(\"READY ✅  Now run:  run_color_tracker(color='green', max_frames=200, debug=True)\")\n"
      ],
      "metadata": {
        "id": "b9XGCmxlo7eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_color_tracker(color='green', max_frames=200, delay=0.12, min_area=1000, debug=True)\n"
      ],
      "metadata": {
        "id": "fGF5AAOMpFav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPLOAD VIDEO FILE\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "4uYnRNAkr2by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# use the exact file name you uploaded\n",
        "cap = cv2.VideoCapture('sample-mp4-file.mp4')\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    annotated, centroid, area = detect_and_track(\n",
        "        frame,\n",
        "        color_name=\"green\",   # change to \"red\", \"blue\", \"yellow\" based on your video\n",
        "        min_area=800,\n",
        "        debug=True\n",
        "    )\n",
        "\n",
        "    cv2_imshow(annotated)\n",
        "\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "31_ZvTwesZjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}